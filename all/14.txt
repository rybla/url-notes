1:"$Sreact.fragment"
2:I[7555,[],""]
3:I[1295,[],""]
5:I[9665,[],"OutletBoundary"]
7:I[4911,[],"AsyncMetadataOutlet"]
9:I[9665,[],"ViewportBoundary"]
b:I[9665,[],"MetadataBoundary"]
c:"$Sreact.suspense"
e:I[8393,[],""]
:HL["/url-notes/_next/static/css/9881504be370c91a.css","style"]
:HL["/url-notes/_next/static/css/0fcde6fa80a72931.css","style"]
0:{"P":null,"b":"TW4j4Ol8KoTfojearZ_lI","p":"/url-notes","c":["","all","14"],"i":false,"f":[[["",{"children":["all",{"children":[["pageIndex","14","d"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/url-notes/_next/static/css/9881504be370c91a.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","className":"$undefined","children":["$","body",null,{"className":"$undefined","children":["$","$L2",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L3",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]}]]}],{"children":["all",["$","$1","c",{"children":[null,["$","$L2",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L3",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["pageIndex","14","d"],["$","$1","c",{"children":[null,["$","$L2",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L3",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$L4",[["$","link","0",{"rel":"stylesheet","href":"/url-notes/_next/static/css/0fcde6fa80a72931.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","$L5",null,{"children":["$L6",["$","$L7",null,{"promise":"$@8"}]]}]]}],{},null,false]},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,[["$","$L9",null,{"children":"$La"}],null],["$","$Lb",null,{"children":["$","div",null,{"hidden":true,"children":["$","$c",null,{"fallback":null,"children":"$Ld"}]}]}]]}],false]],"m":"$undefined","G":["$e",[]],"s":false,"S":true}
a:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
6:null
f:I[6874,["874","static/chunks/874-437a265a67d6cfee.js","216","static/chunks/app/all/%5BpageIndex%5D/page-521ba4b8b4cd9408.js"],""]
24:I[8175,[],"IconMark"]
10:T4f5,Creating new fonts requires a lot of human effort and professional typographic knowledge. Despite the rapid advancements of automatic font generation models, existing methods require users to prepare pre-designed characters with target styles using font-editing software, which poses a problem for non-expert users. To address this limitation, we propose FontCraft, a system that enables font generation without relying on pre-designed characters. Our approach integrates the exploration of a font-style latent space with human-in-the-loop preferential Bayesian optimization and multimodal references, facilitating efficient exploration and enhancing user control. Moreover, FontCraft allows users to revisit previous designs, retracting their earlier choices in the preferential Bayesian optimization process. Once users finish editing the style of a selected character, they can propagate it to the remaining characters and further refine them as needed. The system then generates a complete outline font in OpenType format. We evaluated the effectiveness of FontCraft through a user study comparing it to a baseline interface. Results from both quantitative and qualitative evaluations demonstrate that FontCraft enables non-expert users to design fonts efficiently.11:T519,Table-based reasoning with large language models (LLMs) is a promising direction to tackle many table understanding tasks, such as table-based question answering and fact verification. Compared with generic reasoning, table-based reasoning requires the extraction of underlying semantics from both free-form questions and semi-structured tabular data. Chain-of-Thought and its similar approaches incorporate the reasoning chain in the form of textual context, but it is still an open question how to effectively leverage tabular data in the reasoning chain. We propose the Chain-of-Table framework, where tabular data is explicitly used in the reasoning chain as a proxy for intermediate thoughts. Specifically, we guide LLMs using in-context learning to iteratively generate operations and update the table to represent a tabular reasoning chain. LLMs can therefore dynamically plan the next operation based on the results of the previous ones. This continuous evolution of the table forms a chain, showing the reasoning process for a given tabular problem. The chain carries structured information of the intermediate results, enabling more accurate and reliable predictions. Chain-of-Table achieves new state-of-the-art performance on WikiTQ, FeTaQA, and TabFact benchmarks across multiple LLM choices.4:["$","div",null,{"className":"AppPage_AppPage__MciWo","children":[["$","div",null,{"className":"AppPage_toolbar__H52v2","children":[["$","div",null,{"className":"AppPage_navigation__Luced","children":[["$","div","item-0",{"className":"AppPage_item__vUL6b","children":["$","$Lf","0",{"className":"LinkButton_LinkButton__nW1G0 LinkButton_vertical__B1tIH","href":"/","target":"$undefined","children":"index"}]}],["$","div","sep-0",{"className":"AppPage_item__vUL6b","children":"‚Üê"}],["$","div","item-1",{"className":"AppPage_item__vUL6b","children":["$","$Lf","0",{"className":"LinkButton_LinkButton__nW1G0 LinkButton_vertical__B1tIH","href":"/all/0","target":"$undefined","children":"all"}]}]]}],["$","div",null,{"className":"AppPage_cornerstone__p6Wox"}]]}],["$","div",null,{"className":"AppPage_main__PIVFu","children":[["$","div",null,{"className":"page_previews__BuBMS","children":[["$","div","sep-0",{"className":"page_addedDate__qyLFb","children":"2025-09-12"}],["$","div","0",{"className":"ArticlePreview_ArticlePreview__59E_4","children":[["$","div",null,{"className":"ArticlePreview_title__Snpua","children":["$","$Lf",null,{"href":"https://arxiv.org/abs/2502.11399","target":"_blank","children":"FontCraft: Multimodal Font Design Using Interactive Bayesian Optimization"}]}],"$undefined",["$","div",null,{"className":"ArticlePreview_publishedTime__MauIG","children":["published: ","2025-02-16"]}],["$","div",null,{"className":"ArticlePreview_summary__Zyb4E","children":[["$","p","p-0",{"children":"$10"}]]}],["$","div",null,{"className":"ArticlePreview_footer__lkeLY","children":["$","$Lf",null,{"className":"LinkButton_LinkButton__nW1G0","href":"https://arxiv.org/abs/2502.11399","target":"_blank","children":"üîó"}]}]]}],["$","div","sep-1",{"className":"page_addedDate__qyLFb","children":"2025-09-12"}],["$","div","1",{"className":"ArticlePreview_ArticlePreview__59E_4","children":[["$","div",null,{"className":"ArticlePreview_title__Snpua","children":["$","$Lf",null,{"href":"https://arxiv.org/pdf/2401.04398","target":"_blank","children":"Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding"}]}],"$undefined",["$","div",null,{"className":"ArticlePreview_publishedTime__MauIG","children":["published: ","2024-01-09"]}],["$","div",null,{"className":"ArticlePreview_summary__Zyb4E","children":[["$","p","p-0",{"children":"$11"}]]}],"$L12"]}],"$L13","$L14","$L15","$L16","$L17","$L18","$L19","$L1a","$L1b","$L1c","$L1d","$L1e","$L1f","$L20","$L21","$L22"]}],"$L23"]}]]}]
8:{"metadata":[["$","title","0",{"children":"url-notes | all | page 15 of 113"}],["$","link","1",{"rel":"icon","href":"/url-notes/favicon.ico","type":"image/x-icon","sizes":"256x256"}],["$","$L24","2",{}]],"error":null,"digest":"$undefined"}
d:"$8:metadata"
12:["$","div",null,{"className":"ArticlePreview_footer__lkeLY","children":["$","$Lf",null,{"className":"LinkButton_LinkButton__nW1G0","href":"https://arxiv.org/pdf/2401.04398","target":"_blank","children":"üîó"}]}]
13:["$","div","sep-2",{"className":"page_addedDate__qyLFb","children":"2025-09-12"}]
25:T4c0,Hierarchical structures are popular in recent vision transformers, however, they require sophisticated designs and massive datasets to work well. In this paper, we explore the idea of nesting basic local transformers on non-overlapping image blocks and aggregating them in a hierarchical way. We find that the block aggregation function plays a critical role in enabling cross-block non-local information communication. This observation leads us to design a simplified architecture that requires minor code changes upon the original vision transformer. The benefits of the proposed judiciously-selected design are threefold: (1) NesT converges faster and requires much less training data to achieve good generalization on both ImageNet and small datasets like CIFAR; (2) when extending our key ideas to image generation, NesT leads to a strong decoder that is 8$\times$ faster than previous transformer-based generators; and (3) we show that decoupling the feature learning and abstraction processes via this nested hierarchy in our design enables constructing a novel method (named GradCAT) for visually interpreting the learned model. Source code is available https://github.com/google-research/nested-transformer.14:["$","div","2",{"className":"ArticlePreview_ArticlePreview__59E_4","children":[["$","div",null,{"className":"ArticlePreview_title__Snpua","children":["$","$Lf",null,{"href":"https://arxiv.org/pdf/2105.12723","target":"_blank","children":"Nested Hierarchical Transformer: Towards Accurate, Data-Efficient and Interpretable Visual Understanding"}]}],"$undefined",["$","div",null,{"className":"ArticlePreview_publishedTime__MauIG","children":["published: ","2021-05-26"]}],["$","div",null,{"className":"ArticlePreview_summary__Zyb4E","children":[["$","p","p-0",{"children":"$25"}]]}],["$","div",null,{"className":"ArticlePreview_footer__lkeLY","children":["$","$Lf",null,{"className":"LinkButton_LinkButton__nW1G0","href":"https://arxiv.org/pdf/2105.12723","target":"_blank","children":"üîó"}]}]]}]
15:["$","div","sep-3",{"className":"page_addedDate__qyLFb","children":"2025-09-12"}]
16:["$","div","3",{"className":"ArticlePreview_ArticlePreview__59E_4","children":[["$","div",null,{"className":"ArticlePreview_title__Snpua","children":["$","$Lf",null,{"href":"https://research.google/blog/introducing-google-research-football-a-novel-reinforcement-learning-environment/","target":"_blank","children":"Introducing Google Research Football: A Novel Reinforcement Learning Environment"}]}],"$undefined","$undefined",["$","div",null,{"className":"ArticlePreview_summary__Zyb4E","children":[["$","p","p-0",{"children":"Posted by Karol Kurach, Research Lead and Olivier Bachem, Research Scientist, Google Research, Z√ºrich   The goal of reinforcement learning (RL) is ..."}]]}],["$","div",null,{"className":"ArticlePreview_footer__lkeLY","children":["$","$Lf",null,{"className":"LinkButton_LinkButton__nW1G0","href":"https://research.google/blog/introducing-google-research-football-a-novel-reinforcement-learning-environment/","target":"_blank","children":"üîó"}]}]]}]
17:["$","div","sep-4",{"className":"page_addedDate__qyLFb","children":"2025-09-12"}]
18:["$","div","4",{"className":"ArticlePreview_ArticlePreview__59E_4","children":[["$","div",null,{"className":"ArticlePreview_title__Snpua","children":["$","$Lf",null,{"href":"https://aclanthology.org/2020.acl-demos.29.pdf","target":"_blank","children":"Usnea: An Authorship Tool for Interactive Fiction using Retrieval Based Semantic Parsing"}]}],"$undefined",["$","div",null,{"className":"ArticlePreview_publishedTime__MauIG","children":["published: ","D:20200521164711Z"]}],["$","div",null,{"className":"ArticlePreview_summary__Zyb4E","children":[["$","ul","ul-0",{"children":["\n",["$","li","li-0",{"children":[["$","strong","strong-0",{"children":"Tool:"}]," Usnea, an open-source authoring tool for Interactive Fiction (IF)."]}],"\n",["$","li","li-1",{"children":[["$","strong","strong-0",{"children":"Core Technique:"}]," Integrates retrieval-based semantic parsing with traditional branching story structures."]}],"\n",["$","li","li-2",{"children":[["$","strong","strong-0",{"children":"Mechanism:"}],"\n",["$","ul","ul-0",{"children":["\n",["$","li","li-0",{"children":"Uses a nearest neighbor classification variant with inverse semantic similarity as its distance metric (semantic kernel)."}],"\n",["$","li","li-1",{"children":"Authors define the parser by providing string exemplars paired with class labels."}],"\n",["$","li","li-2",{"children":"This avoids the need for formal semantic representations (e.g., FrameNet) or an ML background."}],"\n"]}],"\n"]}],"\n",["$","li","li-3",{"children":[["$","strong","strong-0",{"children":"Benefit:"}]," Relaxes the strict lexical options of existing IF systems, allowing for more freeform reader input that is semantically, rather than lexically, matched to author-defined exemplars."]}],"\n"]}]]}],["$","div",null,{"className":"ArticlePreview_footer__lkeLY","children":["$","$Lf",null,{"className":"LinkButton_LinkButton__nW1G0","href":"https://aclanthology.org/2020.acl-demos.29.pdf","target":"_blank","children":"üîó"}]}]]}]
19:["$","div","sep-5",{"className":"page_addedDate__qyLFb","children":"2025-09-12"}]
26:T4fe,World modeling has become a cornerstone in AI research, enabling agents to understand, represent, and predict the dynamic environments they inhabit. While prior work largely emphasizes generative methods for 2D image and video data, they overlook the rapidly growing body of work that leverages native 3D and 4D representations such as RGB-D imagery, occupancy grids, and LiDAR point clouds for large-scale scene modeling. At the same time, the absence of a standardized definition and taxonomy for ``world models'' has led to fragmented and sometimes inconsistent claims in the literature. This survey addresses these gaps by presenting the first comprehensive review explicitly dedicated to 3D and 4D world modeling and generation. We establish precise definitions, introduce a structured taxonomy spanning video-based (VideoGen), occupancy-based (OccGen), and LiDAR-based (LiDARGen) approaches, and systematically summarize datasets and evaluation metrics tailored to 3D/4D settings. We further discuss practical applications, identify open challenges, and highlight promising research directions, aiming to provide a coherent and foundational reference for advancing the field. A systematic summary of existing literature is available at https://github.com/worldbench/survey1a:["$","div","5",{"className":"ArticlePreview_ArticlePreview__59E_4","children":[["$","div",null,{"className":"ArticlePreview_title__Snpua","children":["$","$Lf",null,{"href":"https://arxiv.org/abs/2509.07996","target":"_blank","children":"3D and 4D World Modeling: A Survey"}]}],"$undefined",["$","div",null,{"className":"ArticlePreview_publishedTime__MauIG","children":["published: ","2025-09-04"]}],["$","div",null,{"className":"ArticlePreview_summary__Zyb4E","children":[["$","p","p-0",{"children":"$26"}]]}],["$","div",null,{"className":"ArticlePreview_footer__lkeLY","children":["$","$Lf",null,{"className":"LinkButton_LinkButton__nW1G0","href":"https://arxiv.org/abs/2509.07996","target":"_blank","children":"üîó"}]}]]}]
1b:["$","div","sep-6",{"className":"page_addedDate__qyLFb","children":"2025-09-11"}]
1c:["$","div","6",{"className":"ArticlePreview_ArticlePreview__59E_4","children":[["$","div",null,{"className":"ArticlePreview_title__Snpua","children":["$","$Lf",null,{"href":"https://www.quantamagazine.org/self-assembly-gets-automated-in-reverse-of-game-of-life-20250910/","target":"_blank","children":"Self-Assembly Gets Automated in Reverse of ‚ÄòGame of Life‚Äô | Quanta Magazine"}]}],["$","div",null,{"className":"ArticlePreview_feedName__3OGE7","children":[["$","span",null,{"className":"ArticlePreview_punctuation__3jr1w","children":"from"}]," ",["$","span",null,{"className":"ArticlePreview_value__gZoAq","children":"Quanta Magazine"}]]}],["$","div",null,{"className":"ArticlePreview_publishedTime__MauIG","children":["published: ","2025-09-10"]}],["$","div",null,{"className":"ArticlePreview_summary__Zyb4E","children":[["$","p","p-0",{"children":"In cellular automata, simple rules create elaborate structures. Now researchers can start with the structures and reverse-engineer the rules."}]]}],["$","div",null,{"className":"ArticlePreview_footer__lkeLY","children":["$","$Lf",null,{"className":"LinkButton_LinkButton__nW1G0","href":"https://www.quantamagazine.org/self-assembly-gets-automated-in-reverse-of-game-of-life-20250910/","target":"_blank","children":"üîó"}]}]]}]
1d:["$","div","sep-7",{"className":"page_addedDate__qyLFb","children":"2025-09-11"}]
1e:["$","div","7",{"className":"ArticlePreview_ArticlePreview__59E_4","children":[["$","div",null,{"className":"ArticlePreview_title__Snpua","children":["$","$Lf",null,{"href":"https://blog.trailofbits.com/2025/09/10/how-sui-move-rethinks-flash-loan-security/","target":"_blank","children":"How Sui Move rethinks flash loan security"}]}],["$","div",null,{"className":"ArticlePreview_feedName__3OGE7","children":[["$","span",null,{"className":"ArticlePreview_punctuation__3jr1w","children":"from"}]," ",["$","span",null,{"className":"ArticlePreview_value__gZoAq","children":"Trail of Bits"}]]}],["$","div",null,{"className":"ArticlePreview_publishedTime__MauIG","children":["published: ","2025-09-10"]}],["$","div",null,{"className":"ArticlePreview_summary__Zyb4E","children":[["$","p","p-0",{"children":"Sui‚Äôs Move language significantly improves flash loan security by replacing Solidity‚Äôs reliance on callbacks and runtime checks with a ‚Äúhot potato‚Äù model that enforces repayment at the compiler level. This shift makes flash loan security a language guarantee rather than a developer responsibility."}]]}],["$","div",null,{"className":"ArticlePreview_footer__lkeLY","children":["$","$Lf",null,{"className":"LinkButton_LinkButton__nW1G0","href":"https://blog.trailofbits.com/2025/09/10/how-sui-move-rethinks-flash-loan-security/","target":"_blank","children":"üîó"}]}]]}]
1f:["$","div","sep-8",{"className":"page_addedDate__qyLFb","children":"2025-09-11"}]
20:["$","div","8",{"className":"ArticlePreview_ArticlePreview__59E_4","children":[["$","div",null,{"className":"ArticlePreview_title__Snpua","children":["$","$Lf",null,{"href":"https://feeds.feedblitz.com/~/924612350/0/marginalrevolution~AIled-job-interviews.html","target":"_blank","children":"AI-led job interviews - Marginal REVOLUTION"}]}],["$","div",null,{"className":"ArticlePreview_feedName__3OGE7","children":[["$","span",null,{"className":"ArticlePreview_punctuation__3jr1w","children":"from"}]," ",["$","span",null,{"className":"ArticlePreview_value__gZoAq","children":"Marginal Revolution"}]]}],["$","div",null,{"className":"ArticlePreview_publishedTime__MauIG","children":["published: ","2025-09-10"]}],["$","div",null,{"className":"ArticlePreview_summary__Zyb4E","children":[["$","p","p-0",{"children":"We study the impact of replacing human recruiters with AI voice agents to conduct job interviews. Partnering with a recruitment firm, we conducted a natural field experiment in which 70,000 applicants were randomly assigned to be interviewed by human recruiters, AI voice agents, or given a choice between the two. In all three conditions, human [‚Ä¶]"}]]}],["$","div",null,{"className":"ArticlePreview_footer__lkeLY","children":["$","$Lf",null,{"className":"LinkButton_LinkButton__nW1G0","href":"https://feeds.feedblitz.com/~/924612350/0/marginalrevolution~AIled-job-interviews.html","target":"_blank","children":"üîó"}]}]]}]
21:["$","div","sep-9",{"className":"page_addedDate__qyLFb","children":"2025-09-11"}]
22:["$","div","9",{"className":"ArticlePreview_ArticlePreview__59E_4","children":[["$","div",null,{"className":"ArticlePreview_title__Snpua","children":["$","$Lf",null,{"href":"https://feeds.feedblitz.com/~/924633947/0/marginalrevolution~Wednesday-assorted-links.html","target":"_blank","children":"Wednesday assorted links - Marginal REVOLUTION"}]}],["$","div",null,{"className":"ArticlePreview_feedName__3OGE7","children":[["$","span",null,{"className":"ArticlePreview_punctuation__3jr1w","children":"from"}]," ",["$","span",null,{"className":"ArticlePreview_value__gZoAq","children":"Marginal Revolution"}]]}],["$","div",null,{"className":"ArticlePreview_publishedTime__MauIG","children":["published: ","2025-09-10"]}],["$","div",null,{"className":"ArticlePreview_summary__Zyb4E","children":[["$","ol","ol-0",{"children":["\n",["$","li","li-0",{"children":"Flora Yuknovich, painter (NYT). 2. Further comments on Milei and Argentina. 3. My TA Zixuan Ma is starting a blog on China and also recommends these six books. 4. How is New College of Florida doing? 5. Some new Substacks from economics graduate students. 6. Machine learning for economists.¬† And double descent and econometrics. [‚Ä¶]"}],"\n"]}]]}],["$","div",null,{"className":"ArticlePreview_footer__lkeLY","children":["$","$Lf",null,{"className":"LinkButton_LinkButton__nW1G0","href":"https://feeds.feedblitz.com/~/924633947/0/marginalrevolution~Wednesday-assorted-links.html","target":"_blank","children":"üîó"}]}]]}]
23:["$","div",null,{"className":"page_toolbar__VAh0U","children":[["$","div",null,{"className":"page_navigation___3IFr","children":[["$","$Lf",null,{"className":"LinkButton_LinkButton__nW1G0","href":"/all/13","target":"$undefined","children":"newer"}],["$","$Lf",null,{"className":"LinkButton_LinkButton__nW1G0","href":"/all/15","target":"$undefined","children":"older"}]]}],["$","div",null,{"className":"page_location__WbWIR","children":[["$","span",null,{"className":"FocusSpan_FocusSpan__MPt_V","children":15}],"/",113]}]]}]
