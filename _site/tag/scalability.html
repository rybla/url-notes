<!DOCTYPE html><!--YCZlAJ7TgA6KuYKvaNG2h--><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/url-notes/_next/static/css/f03c873af434c7c6.css" data-precedence="next"/><link rel="stylesheet" href="/url-notes/_next/static/css/82198f0047596010.css" data-precedence="next"/><link rel="stylesheet" href="/url-notes/_next/static/css/542742ad04044919.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/url-notes/_next/static/chunks/webpack-9fe4f6bea1a8561b.js"/><script src="/url-notes/_next/static/chunks/4bd1b696-cf72ae8a39fa05aa.js" async=""></script><script src="/url-notes/_next/static/chunks/964-a29425d4972030f1.js" async=""></script><script src="/url-notes/_next/static/chunks/main-app-e4d4697bcd6cfe75.js" async=""></script><script src="/url-notes/_next/static/chunks/874-437a265a67d6cfee.js" async=""></script><script src="/url-notes/_next/static/chunks/app/tag/%5Btag%5D/page-3ad24d2a8735be85.js" async=""></script><title>url-notes | tag | scalability</title><script src="/url-notes/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body><div hidden=""><!--$--><!--/$--></div><div class="page_page___hQFP"><div class="page_header__Y1ecl">url-notes | tag | scalability</div><div class="page_content__fAQW6"><div class="page_previews__SpAnf"><div class="ArticlePreview_ArticlePreview__59E_4"><div class="ArticlePreview_title__Snpua"><a target="_blank" href="https://news.ycombinator.com/item?id=44840728">Ask HN: How can ChatGPT serve 700M users when I can&#x27;t run one GPT-4 locally?</a></div><div class="ArticlePreview_tags__y8wnE"><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/llm">llm</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/large%20language%20model">large language model</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/chatgpt">chatgpt</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/gpt-4">gpt-4</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/inference">inference</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/scalability">scalability</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/hardware">hardware</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/gpu">gpu</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/tpu">tpu</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/parallelism">parallelism</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/batching">batching</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/memory%20bandwidth">memory bandwidth</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/model%20optimization">model optimization</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/mixture%20of%20experts">mixture of experts</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/moe">moe</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/quantization">quantization</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/speculative%20decoding">speculative decoding</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/kv%20cache">kv cache</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/economics">economics</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/infrastructure">infrastructure</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/hacker%20news">hacker news</a></div><div class="ArticlePreview_summary__Zyb4E"><ul>
<li>
<p><strong>Batching &amp; Parallelism</strong>:</p>
<ul>
<li>Large-scale inference relies on batching, where multiple user requests are processed simultaneously.</li>
<li>The primary bottleneck in LLM inference is memory bandwidth (loading model weights from VRAM to compute units).</li>
<li>By batching requests, weights are loaded once and applied to many queries, amortizing the high cost of memory access and dramatically increasing throughput.</li>
<li>This process is highly parallelizable across large clusters of GPUs.</li>
</ul>
</li>
<li>
<p><strong>Hardware &amp; Infrastructure</strong>:</p>
<ul>
<li>Massive investment in specialized hardware like NVIDIA H100s or Google TPUs, which feature large amounts of high-bandwidth memory (HBM).</li>
<li>Models are sharded (split) across multiple GPUs (tensor and pipeline parallelism), so a single model runs on a cluster of interconnected accelerators.</li>
<li>The infrastructure is built for high utilization, unlike a local setup which is mostly idle.</li>
</ul>
</li>
<li>
<p><strong>Model Optimizations</strong>:</p>
<ul>
<li><strong>Mixture of Experts (MoE)</strong>: Models are designed so that only a fraction of the total parameters (the &quot;experts&quot;) are activated for any given token, reducing the computational cost per inference.</li>
<li><strong>Quantization</strong>: Model weights are compressed to lower-precision formats (e.g., INT8, FP8) to reduce memory footprint and bandwidth requirements.</li>
<li><strong>Speculative Decoding</strong>: A smaller, faster &quot;draft&quot; model generates candidate tokens which are then validated in parallel by the larger, more powerful model, increasing token generation speed.</li>
<li><strong>KV Cache</strong>: The key-value state of the attention mechanism is cached, so the context doesn&#x27;t need to be re-processed for each new token generated in a sequence.</li>
</ul>
</li>
<li>
<p><strong>Economic Model</strong>:</p>
<ul>
<li>The operation is funded by billions of dollars in investment, allowing companies to run at a loss to capture market share.</li>
<li>The cost per user is manageable because of the efficiencies of scale and because the vast majority of users are idle most of the time, allowing for high multi-tenancy on the hardware.</li>
</ul>
</li>
</ul></div></div><div class="ArticlePreview_ArticlePreview__59E_4"><div class="ArticlePreview_title__Snpua"><a target="_blank" href="https://blog.hyperknot.com/p/openfreemap-survived-100000-requests">OpenFreeMap survived 100,000 requests per second</a></div><div class="ArticlePreview_tags__y8wnE"><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/ddos">ddos</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/traffic%20spike">traffic spike</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/scalability">scalability</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/performance">performance</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/nginx">nginx</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/server%20administration">server administration</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/system%20administration">system administration</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/linux">linux</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/troubleshooting">troubleshooting</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/debugging">debugging</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/cloudflare">cloudflare</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/cdn">cdn</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/caching">caching</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/resilience">resilience</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/high%20availability">high availability</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/bots">bots</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/abuse">abuse</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/web%20scraping">web scraping</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/rate%20limiting">rate limiting</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/firewall">firewall</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/security">security</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/server%20configuration">server configuration</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/tuning">tuning</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/openfreemap">openfreemap</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/incident%20report">incident report</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/postmortem">postmortem</a></div><div class="ArticlePreview_summary__Zyb4E"><ul>
<li><strong>Incident</strong>: OpenFreeMap, a map tile service, experienced a sudden traffic surge to 100,000 requests/second (3 billion requests/24h), caused by a viral web application, <code>Wplace.live</code>.</li>
<li><strong>System Failure</strong>: The <code>nginx</code> server began failing with <code>(24: Too many open files)</code> errors due to the excessive load.</li>
<li><strong>Architecture &amp; Resilience</strong>:<!-- -->
<ul>
<li>The stack consists of Hetzner servers, <code>nginx</code>, and Btrfs for file storage.</li>
<li>Cloudflare is used as a CDN and sponsor.</li>
<li>Despite the file handle errors, the system remained largely operational, achieving a 96% success rate on requests.</li>
<li>The CDN maintained a 99.4% cache hit ratio; origin servers handled the remaining ~1,000 requests/second.</li>
</ul>
</li>
<li><strong>Root Cause Analysis</strong>: The traffic from <code>Wplace.live</code> was attributed to scripting (e.g., Puppeteer), causing an abnormally high number of requests per user (avg. 1,500).</li>
<li><strong>Mitigation &amp; Future Plans</strong>:<!-- -->
<ul>
<li>A Cloudflare rule was implemented to block the offending referrer.</li>
<li>Future plans include implementing automated, referrer-based rate limiting via the Cloudflare API.</li>
<li>Server configuration will be tuned to increase the open file limit to prevent similar failures.</li>
</ul>
</li>
</ul></div></div></div></div></div><!--$--><!--/$--><script src="/url-notes/_next/static/chunks/webpack-9fe4f6bea1a8561b.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[7555,[],\"\"]\n3:I[1295,[],\"\"]\n5:I[9665,[],\"OutletBoundary\"]\n7:I[4911,[],\"AsyncMetadataOutlet\"]\n9:I[9665,[],\"ViewportBoundary\"]\nb:I[9665,[],\"MetadataBoundary\"]\nc:\"$Sreact.suspense\"\ne:I[8393,[],\"\"]\n:HL[\"/url-notes/_next/static/css/f03c873af434c7c6.css\",\"style\"]\n:HL[\"/url-notes/_next/static/css/82198f0047596010.css\",\"style\"]\n:HL[\"/url-notes/_next/static/css/542742ad04044919.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"YCZlAJ7TgA6KuYKvaNG2h\",\"p\":\"/url-notes\",\"c\":[\"\",\"tag\",\"scalability\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"tag\",{\"children\":[[\"tag\",\"scalability\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/url-notes/_next/static/css/f03c873af434c7c6.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"children\":[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]}]]}],{\"children\":[\"tag\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"tag\",\"scalability\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$L4\",[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/url-notes/_next/static/css/82198f0047596010.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"link\",\"1\",{\"rel\":\"stylesheet\",\"href\":\"/url-notes/_next/static/css/542742ad04044919.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"$L5\",null,{\"children\":[\"$L6\",[\"$\",\"$L7\",null,{\"promise\":\"$@8\"}]]}]]}],{},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[[\"$\",\"$L9\",null,{\"children\":\"$La\"}],null],[\"$\",\"$Lb\",null,{\"children\":[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$c\",null,{\"fallback\":null,\"children\":\"$Ld\"}]}]}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$e\",[]],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"f:I[6874,[\"874\",\"static/chunks/874-437a265a67d6cfee.js\",\"296\",\"static/chunks/app/tag/%5Btag%5D/page-3ad24d2a8735be85.js\"],\"\"]\n"])</script><script>self.__next_f.push([1,"4:[\"$\",\"div\",null,{\"className\":\"page_page___hQFP\",\"children\":[[\"$\",\"div\",null,{\"className\":\"page_header__Y1ecl\",\"children\":\"url-notes | tag | scalability\"}],[\"$\",\"div\",null,{\"className\":\"page_content__fAQW6\",\"children\":[\"$\",\"div\",null,{\"className\":\"page_previews__SpAnf\",\"children\":[[\"$\",\"div\",\"0\",{\"className\":\"ArticlePreview_ArticlePreview__59E_4\",\"children\":[[\"$\",\"div\",null,{\"className\":\"ArticlePreview_title__Snpua\",\"children\":[\"$\",\"$Lf\",null,{\"href\":\"https://news.ycombinator.com/item?id=44840728\",\"target\":\"_blank\",\"children\":\"Ask HN: How can ChatGPT serve 700M users when I can't run one GPT-4 locally?\"}]}],[\"$\",\"div\",null,{\"className\":\"ArticlePreview_tags__y8wnE\",\"children\":[[\"$\",\"$Lf\",\"0\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/llm\",\"children\":\"llm\"}],[\"$\",\"$Lf\",\"1\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/large%20language%20model\",\"children\":\"large language model\"}],[\"$\",\"$Lf\",\"2\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/chatgpt\",\"children\":\"chatgpt\"}],[\"$\",\"$Lf\",\"3\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/gpt-4\",\"children\":\"gpt-4\"}],[\"$\",\"$Lf\",\"4\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/inference\",\"children\":\"inference\"}],[\"$\",\"$Lf\",\"5\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/scalability\",\"children\":\"scalability\"}],[\"$\",\"$Lf\",\"6\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/hardware\",\"children\":\"hardware\"}],[\"$\",\"$Lf\",\"7\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/gpu\",\"children\":\"gpu\"}],[\"$\",\"$Lf\",\"8\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/tpu\",\"children\":\"tpu\"}],[\"$\",\"$Lf\",\"9\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/parallelism\",\"children\":\"parallelism\"}],[\"$\",\"$Lf\",\"10\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/batching\",\"children\":\"batching\"}],[\"$\",\"$Lf\",\"11\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/memory%20bandwidth\",\"children\":\"memory bandwidth\"}],[\"$\",\"$Lf\",\"12\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/model%20optimization\",\"children\":\"model optimization\"}],[\"$\",\"$Lf\",\"13\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/mixture%20of%20experts\",\"children\":\"mixture of experts\"}],[\"$\",\"$Lf\",\"14\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/moe\",\"children\":\"moe\"}],[\"$\",\"$Lf\",\"15\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/quantization\",\"children\":\"quantization\"}],[\"$\",\"$Lf\",\"16\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/speculative%20decoding\",\"children\":\"speculative decoding\"}],[\"$\",\"$Lf\",\"17\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/kv%20cache\",\"children\":\"kv cache\"}],[\"$\",\"$Lf\",\"18\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/economics\",\"children\":\"economics\"}],[\"$\",\"$Lf\",\"19\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/infrastructure\",\"children\":\"infrastructure\"}],[\"$\",\"$Lf\",\"20\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/hacker%20news\",\"children\":\"hacker news\"}]]}],[\"$\",\"div\",null,{\"className\":\"ArticlePreview_summary__Zyb4E\",\"children\":[[\"$\",\"ul\",\"ul-0\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":[\"\\n\",[\"$\",\"p\",\"p-0\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Batching \u0026 Parallelism\"}],\":\"]}],\"\\n\",[\"$\",\"ul\",\"ul-0\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":\"Large-scale inference relies on batching, where multiple user requests are processed simultaneously.\"}],\"\\n\",[\"$\",\"li\",\"li-1\",{\"children\":\"The primary bottleneck in LLM inference is memory bandwidth (loading model weights from VRAM to compute units).\"}],\"\\n\",[\"$\",\"li\",\"li-2\",{\"children\":\"By batching requests, weights are loaded once and applied to many queries, amortizing the high cost of memory access and dramatically increasing throughput.\"}],\"\\n\",[\"$\",\"li\",\"li-3\",{\"children\":\"This process is highly parallelizable across large clusters of GPUs.\"}],\"\\n\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"li\",\"li-1\",{\"children\":[\"\\n\",[\"$\",\"p\",\"p-0\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Hardware \u0026 Infrastructure\"}],\":\"]}],\"\\n\",[\"$\",\"ul\",\"ul-0\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":\"Massive investment in specialized hardware like NVIDIA H100s or Google TPUs, which feature large amounts of high-bandwidth memory (HBM).\"}],\"\\n\",[\"$\",\"li\",\"li-1\",{\"children\":\"Models are sharded (split) across multiple GPUs (tensor and pipeline parallelism), so a single model runs on a cluster of interconnected accelerators.\"}],\"\\n\",\"$L10\",\"\\n\"]}],\"\\n\"]}],\"\\n\",\"$L11\",\"\\n\",\"$L12\",\"\\n\"]}]]}]]}],\"$L13\"]}]}]]}]\n"])</script><script>self.__next_f.push([1,"10:[\"$\",\"li\",\"li-2\",{\"children\":\"The infrastructure is built for high utilization, unlike a local setup which is mostly idle.\"}]\n"])</script><script>self.__next_f.push([1,"11:[\"$\",\"li\",\"li-2\",{\"children\":[\"\\n\",[\"$\",\"p\",\"p-0\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Model Optimizations\"}],\":\"]}],\"\\n\",[\"$\",\"ul\",\"ul-0\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Mixture of Experts (MoE)\"}],\": Models are designed so that only a fraction of the total parameters (the \\\"experts\\\") are activated for any given token, reducing the computational cost per inference.\"]}],\"\\n\",[\"$\",\"li\",\"li-1\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Quantization\"}],\": Model weights are compressed to lower-precision formats (e.g., INT8, FP8) to reduce memory footprint and bandwidth requirements.\"]}],\"\\n\",[\"$\",\"li\",\"li-2\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Speculative Decoding\"}],\": A smaller, faster \\\"draft\\\" model generates candidate tokens which are then validated in parallel by the larger, more powerful model, increasing token generation speed.\"]}],\"\\n\",[\"$\",\"li\",\"li-3\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"KV Cache\"}],\": The key-value state of the attention mechanism is cached, so the context doesn't need to be re-processed for each new token generated in a sequence.\"]}],\"\\n\"]}],\"\\n\"]}]\n"])</script><script>self.__next_f.push([1,"12:[\"$\",\"li\",\"li-3\",{\"children\":[\"\\n\",[\"$\",\"p\",\"p-0\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Economic Model\"}],\":\"]}],\"\\n\",[\"$\",\"ul\",\"ul-0\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":\"The operation is funded by billions of dollars in investment, allowing companies to run at a loss to capture market share.\"}],\"\\n\",[\"$\",\"li\",\"li-1\",{\"children\":\"The cost per user is manageable because of the efficiencies of scale and because the vast majority of users are idle most of the time, allowing for high multi-tenancy on the hardware.\"}],\"\\n\"]}],\"\\n\"]}]\n"])</script><script>self.__next_f.push([1,"13:[\"$\",\"div\",\"1\",{\"className\":\"ArticlePreview_ArticlePreview__59E_4\",\"children\":[[\"$\",\"div\",null,{\"className\":\"ArticlePreview_title__Snpua\",\"children\":[\"$\",\"$Lf\",null,{\"href\":\"https://blog.hyperknot.com/p/openfreemap-survived-100000-requests\",\"target\":\"_blank\",\"children\":\"OpenFreeMap survived 100,000 requests per second\"}]}],[\"$\",\"div\",null,{\"className\":\"ArticlePreview_tags__y8wnE\",\"children\":[[\"$\",\"$Lf\",\"0\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/ddos\",\"children\":\"ddos\"}],[\"$\",\"$Lf\",\"1\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/traffic%20spike\",\"children\":\"traffic spike\"}],[\"$\",\"$Lf\",\"2\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/scalability\",\"children\":\"scalability\"}],[\"$\",\"$Lf\",\"3\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/performance\",\"children\":\"performance\"}],[\"$\",\"$Lf\",\"4\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/nginx\",\"children\":\"nginx\"}],[\"$\",\"$Lf\",\"5\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/server%20administration\",\"children\":\"server administration\"}],[\"$\",\"$Lf\",\"6\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/system%20administration\",\"children\":\"system administration\"}],[\"$\",\"$Lf\",\"7\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/linux\",\"children\":\"linux\"}],[\"$\",\"$Lf\",\"8\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/troubleshooting\",\"children\":\"troubleshooting\"}],[\"$\",\"$Lf\",\"9\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/debugging\",\"children\":\"debugging\"}],[\"$\",\"$Lf\",\"10\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/cloudflare\",\"children\":\"cloudflare\"}],[\"$\",\"$Lf\",\"11\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/cdn\",\"children\":\"cdn\"}],[\"$\",\"$Lf\",\"12\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/caching\",\"children\":\"caching\"}],[\"$\",\"$Lf\",\"13\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/resilience\",\"children\":\"resilience\"}],[\"$\",\"$Lf\",\"14\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/high%20availability\",\"children\":\"high availability\"}],[\"$\",\"$Lf\",\"15\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/bots\",\"children\":\"bots\"}],[\"$\",\"$Lf\",\"16\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/abuse\",\"children\":\"abuse\"}],[\"$\",\"$Lf\",\"17\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/web%20scraping\",\"children\":\"web scraping\"}],[\"$\",\"$Lf\",\"18\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/rate%20limiting\",\"children\":\"rate limiting\"}],[\"$\",\"$Lf\",\"19\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/firewall\",\"children\":\"firewall\"}],[\"$\",\"$Lf\",\"20\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/security\",\"children\":\"security\"}],[\"$\",\"$Lf\",\"21\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/server%20configuration\",\"children\":\"server configuration\"}],[\"$\",\"$Lf\",\"22\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/tuning\",\"children\":\"tuning\"}],[\"$\",\"$Lf\",\"23\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/openfreemap\",\"children\":\"openfreemap\"}],[\"$\",\"$Lf\",\"24\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/incident%20report\",\"children\":\"incident report\"}],[\"$\",\"$Lf\",\"25\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/postmortem\",\"children\":\"postmortem\"}]]}],[\"$\",\"div\",null,{\"className\":\"ArticlePreview_summary__Zyb4E\",\"children\":[[\"$\",\"ul\",\"ul-0\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Incident\"}],\": OpenFreeMap, a map tile service, experienced a sudden traffic surge to 100,000 requests/second (3 billion requests/24h), caused by a viral web application, \",[\"$\",\"code\",\"code-0\",{\"children\":\"Wplace.live\"}],\".\"]}],\"\\n\",[\"$\",\"li\",\"li-1\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"System Failure\"}],\": The \",[\"$\",\"code\",\"code-0\",{\"children\":\"nginx\"}],\" server began failing with \",[\"$\",\"code\",\"code-1\",{\"children\":\"(24: Too many open files)\"}],\" errors due to the excessive load.\"]}],\"\\n\",[\"$\",\"li\",\"li-2\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Architecture \u0026 Resilience\"}],\":\",\"\\n\",[\"$\",\"ul\",\"ul-0\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":[\"The stack consists of Hetzner servers, \",[\"$\",\"code\",\"code-0\",{\"children\":\"nginx\"}],\", and Btrfs for file storage.\"]}],\"\\n\",[\"$\",\"li\",\"li-1\",{\"children\":\"Cloudflare is used as a CDN and sponsor.\"}],\"\\n\",[\"$\",\"li\",\"li-2\",{\"children\":\"Despite the file handle errors, the system remained largely operational, achieving a 96% success rate on requests.\"}],\"\\n\",\"$L14\",\"\\n\"]}],\"\\n\"]}],\"\\n\",\"$L15\",\"\\n\",\"$L16\",\"\\n\"]}]]}]]}]\n"])</script><script>self.__next_f.push([1,"14:[\"$\",\"li\",\"li-3\",{\"children\":\"The CDN maintained a 99.4% cache hit ratio; origin servers handled the remaining ~1,000 requests/second.\"}]\n15:[\"$\",\"li\",\"li-3\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Root Cause Analysis\"}],\": The traffic from \",[\"$\",\"code\",\"code-0\",{\"children\":\"Wplace.live\"}],\" was attributed to scripting (e.g., Puppeteer), causing an abnormally high number of requests per user (avg. 1,500).\"]}]\n16:[\"$\",\"li\",\"li-4\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Mitigation \u0026 Future Plans\"}],\":\",\"\\n\",[\"$\",\"ul\",\"ul-0\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":\"A Cloudflare rule was implemented to block the offending referrer.\"}],\"\\n\",[\"$\",\"li\",\"li-1\",{\"children\":\"Future plans include implementing automated, referrer-based rate limiting via the Cloudflare API.\"}],\"\\n\",[\"$\",\"li\",\"li-2\",{\"children\":\"Server configuration will be tuned to increase the open file limit to prevent similar failures.\"}],\"\\n\"]}],\"\\n\"]}]\n"])</script><script>self.__next_f.push([1,"a:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n6:null\n"])</script><script>self.__next_f.push([1,"8:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"url-notes | tag | scalability\"}]],\"error\":null,\"digest\":\"$undefined\"}\n"])</script><script>self.__next_f.push([1,"d:\"$8:metadata\"\n"])</script></body></html>