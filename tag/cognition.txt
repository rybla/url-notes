1:"$Sreact.fragment"
2:I[7555,[],""]
3:I[1295,[],""]
5:I[9665,[],"OutletBoundary"]
7:I[4911,[],"AsyncMetadataOutlet"]
9:I[9665,[],"ViewportBoundary"]
b:I[9665,[],"MetadataBoundary"]
c:"$Sreact.suspense"
e:I[8393,[],""]
:HL["/url-notes/_next/static/css/f03c873af434c7c6.css","style"]
:HL["/url-notes/_next/static/css/0e5ea1ea0183b412.css","style"]
:HL["/url-notes/_next/static/css/7190d9c623ab1fe0.css","style"]
0:{"P":null,"b":"5-nUCfWPKUbKZCqW3krM4","p":"/url-notes","c":["","tag","cognition"],"i":false,"f":[[["",{"children":["tag",{"children":[["tag","cognition","d"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/url-notes/_next/static/css/f03c873af434c7c6.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","children":["$","body",null,{"children":["$","$L2",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L3",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]}]]}],{"children":["tag",["$","$1","c",{"children":[null,["$","$L2",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L3",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["tag","cognition","d"],["$","$1","c",{"children":[null,["$","$L2",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L3",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$L4",[["$","link","0",{"rel":"stylesheet","href":"/url-notes/_next/static/css/0e5ea1ea0183b412.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}],["$","link","1",{"rel":"stylesheet","href":"/url-notes/_next/static/css/7190d9c623ab1fe0.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","$L5",null,{"children":["$L6",["$","$L7",null,{"promise":"$@8"}]]}]]}],{},null,false]},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,[["$","$L9",null,{"children":"$La"}],null],["$","$Lb",null,{"children":["$","div",null,{"hidden":true,"children":["$","$c",null,{"fallback":null,"children":"$Ld"}]}]}]]}],false]],"m":"$undefined","G":["$e",[]],"s":false,"S":true}
a:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
6:null
f:I[8175,[],"IconMark"]
8:{"metadata":[["$","title","0",{"children":"url-notes | tag | cognition"}],["$","link","1",{"rel":"icon","href":"/url-notes/favicon.ico","type":"image/x-icon","sizes":"256x256"}],["$","$Lf","2",{}]],"error":null,"digest":"$undefined"}
d:"$8:metadata"
10:I[6874,["874","static/chunks/874-437a265a67d6cfee.js","296","static/chunks/app/tag/%5Btag%5D/page-abef1952a2d9d9ae.js"],""]
4:["$","div",null,{"className":"$undefined","children":[["$","div",null,{"className":"Header_Header__VDN4T","children":[["$","div",null,{"className":"Header_item__PWJos","children":["$","$L10",null,{"href":"/","children":"url-notes"}]}],[[["$","div","separator-0",{"className":"Header_separator__zF22U","children":"|"}],["$","div","item-0",{"className":"Header_item__PWJos","children":["$","$L10","0",{"href":"/tags","children":"tag"}]}]],[["$","div","separator-1",{"className":"Header_separator__zF22U","children":"|"}],["$","div","item-1",{"className":"Header_item__PWJos","children":["$","$L10","1",{"href":"/tags","children":"tag"}]}]],[["$","div","separator-2",{"className":"Header_separator__zF22U","children":"|"}],["$","div","item-2",{"className":"Header_item__PWJos","children":["$","span","2",{"children":"cognition"}]}]]]]}],["$","div",null,{"className":"page_content__fAQW6","children":["$","div",null,{"className":"page_previews__SpAnf","children":[["$","div","0",{"className":"ArticlePreview_ArticlePreview__59E_4","children":[["$","div",null,{"className":"ArticlePreview_title__Snpua","children":["$","$L10",null,{"href":"https://zed.dev/blog/why-llms-cant-build-software","target":"_blank","children":"Why LLMs Can't Really Build Software - Zed Blog"}]}],["$","div",null,{"className":"ArticlePreview_tags__y8wnE","children":[["$","$L10","0",{"className":"ArticlePreview_tag___oIyn","href":"/tag/llm","children":"llm"}],["$","$L10","1",{"className":"ArticlePreview_tag___oIyn","href":"/tag/software%20engineering","children":"software engineering"}],["$","$L10","2",{"className":"ArticlePreview_tag___oIyn","href":"/tag/mental%20models","children":"mental models"}],["$","$L10","3",{"className":"ArticlePreview_tag___oIyn","href":"/tag/ai","children":"ai"}],["$","$L10","4",{"className":"ArticlePreview_tag___oIyn","href":"/tag/programming","children":"programming"}],["$","$L10","5",{"className":"ArticlePreview_tag___oIyn","href":"/tag/ai%20limitations","children":"ai limitations"}],["$","$L10","6",{"className":"ArticlePreview_tag___oIyn","href":"/tag/autonomous%20agents","children":"autonomous agents"}],["$","$L10","7",{"className":"ArticlePreview_tag___oIyn","href":"/tag/cognition","children":"cognition"}],["$","$L10","8",{"className":"ArticlePreview_tag___oIyn","href":"/tag/software%20development","children":"software development"}]]}],["$","div",null,{"className":"ArticlePreview_summary__Zyb4E","children":[["$","ul","ul-0",{"children":["\n",["$","li","li-0",{"children":[["$","strong","strong-0",{"children":"Core Thesis:"}]," LLMs cannot effectively build non-trivial software because they are incapable of creating, maintaining, and comparing the two distinct mental models essential for engineering: the model of the ",["$","em","em-0",{"children":"requirements"}]," and the model of what the ",["$","em","em-1",{"children":"code actually does"}],"."]}],"\n",["$","li","li-1",{"children":[["$","strong","strong-0",{"children":"Effective Software Engineering Loop:"}],"\n",["$","ol","ol-0",{"children":["\n",["$","li","li-0",{"children":"Build a mental model of requirements."}],"\n",["$","li","li-1",{"children":"Write code to implement the model."}],"\n",["$","li","li-2",{"children":"Build a mental model of the code's actual behavior."}],"\n",["$","li","li-3",{"children":"Identify discrepancies and iterate on code or requirements."}],"\n"]}],"\n"]}],"\n",["$","li","li-2",{"children":[["$","strong","strong-0",{"children":"LLM Failures in the Loop:"}],"\n",["$","ul","ul-0",{"children":["\n",["$","li","li-0",{"children":"LLMs cannot reliably perform step 3 or 4. They struggle to form an accurate model of the code they've written and get confused when tests fail, guessing whether to fix the code or the tests."}],"\n",["$","li","li-1",{"children":"They lack the ability to \"zoom\" in and out of context levels or to temporarily stash a problem's context to solve a sub-problem, unlike human engineers."}],"\n"]}],"\n"]}],"\n",["$","li","li-3",{"children":[["$","strong","strong-0",{"children":"Identified Technical Weaknesses:"}],"\n",["$","ul","ul-0",{"children":["\n",["$","li","li-0",{"children":[["$","strong","strong-0",{"children":"Context Omission:"}]," Models fail to acquire relevant context that is not explicitly provided."]}],"\n",["$","li","li-1",{"children":["$L11"," Model outputs are disproportionately influenced by the most recent information in the context window."]}],"\n","$L12","\n"]}],"\n"]}],"\n","$L13","\n"]}]]}]]}]]}]}]]}]
11:["$","strong","strong-0",{"children":"Recency Bias:"}]
12:["$","li","li-2",{"children":[["$","strong","strong-0",{"children":"Hallucination:"}]," Models generate plausible but incorrect details."]}]
13:["$","li","li-4",{"children":[["$","strong","strong-0",{"children":"Conclusion:"}]," While useful for generating code for simple, well-defined tasks, LLMs currently function as a tool, not an autonomous engineer. The human developer remains responsible for driving the development process by managing the core mental models and verifying the output."]}]
