<!DOCTYPE html><!--5_nUCfWPKUbKZCqW3krM4--><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/url-notes/_next/static/css/f03c873af434c7c6.css" data-precedence="next"/><link rel="stylesheet" href="/url-notes/_next/static/css/0e5ea1ea0183b412.css" data-precedence="next"/><link rel="stylesheet" href="/url-notes/_next/static/css/7190d9c623ab1fe0.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/url-notes/_next/static/chunks/webpack-54d9d4b2aa649176.js"/><script src="/url-notes/_next/static/chunks/4bd1b696-cf72ae8a39fa05aa.js" async=""></script><script src="/url-notes/_next/static/chunks/964-a29425d4972030f1.js" async=""></script><script src="/url-notes/_next/static/chunks/main-app-e4d4697bcd6cfe75.js" async=""></script><script src="/url-notes/_next/static/chunks/874-437a265a67d6cfee.js" async=""></script><script src="/url-notes/_next/static/chunks/app/tag/%5Btag%5D/page-abef1952a2d9d9ae.js" async=""></script><title>url-notes | tag | pricing</title><link rel="icon" href="/url-notes/favicon.ico" type="image/x-icon" sizes="256x256"/><script src="/url-notes/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body><div hidden=""><!--$--><!--/$--></div><div><div class="Header_Header__VDN4T"><div class="Header_item__PWJos"><a href="/url-notes">url-notes</a></div><div class="Header_separator__zF22U">|</div><div class="Header_item__PWJos"><a href="/url-notes/tags">tag</a></div><div class="Header_separator__zF22U">|</div><div class="Header_item__PWJos"><a href="/url-notes/tags">tag</a></div><div class="Header_separator__zF22U">|</div><div class="Header_item__PWJos"><span>pricing</span></div></div><div class="page_content__fAQW6"><div class="page_previews__SpAnf"><div class="ArticlePreview_ArticlePreview__59E_4"><div class="ArticlePreview_title__Snpua"><a target="_blank" href="https://simonwillison.net/2025/Aug/7/gpt-5/">GPT-5: Key characteristics, pricing and model card</a></div><div class="ArticlePreview_tags__y8wnE"><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/ai">ai</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/gpt-5">gpt-5</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/large%20language%20models">large language models</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/openai">openai</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/machine%20learning">machine learning</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/technology">technology</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/api">api</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/pricing">pricing</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/ai%20safety">ai safety</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/prompt%20injection">prompt injection</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/reasoning">reasoning</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/multimodality">multimodality</a></div><div class="ArticlePreview_summary__Zyb4E"><ul>
<li>
<p><strong>Model Architecture</strong>:</p>
<ul>
<li><strong>ChatGPT Interface</strong>: A hybrid system using a real-time router to select between a &quot;smart and fast&quot; model for most queries and a &quot;deeper reasoning&quot; model for complex problems. A &quot;mini&quot; version is used when usage limits are reached.</li>
<li><strong>API Access</strong>: Offered as three distinct models: <code>gpt-5</code> (regular), <code>gpt-5-mini</code>, and <code>gpt-5-nano</code>.</li>
<li><strong>Reasoning Levels</strong>: Each API model can be configured with four reasoning levels: minimal, low, medium, or high.</li>
</ul>
</li>
<li>
<p><strong>Technical Specifications</strong>:</p>
<ul>
<li><strong>Context Window</strong>: 272,000 input tokens.</li>
<li><strong>Output Limit</strong>: 128,000 tokens (includes &quot;invisible&quot; reasoning tokens).</li>
<li><strong>Modalities</strong>: Supports text and image input; text-only output.</li>
<li><strong>Knowledge Cutoff</strong>: September 30, 2024 for GPT-5; May 30, 2024 for mini and nano versions.</li>
</ul>
</li>
<li>
<p><strong>Pricing (per million tokens)</strong>:</p>
<ul>
<li><strong>GPT-5</strong>: $1.25 input / $10.00 output.</li>
<li><strong>GPT-5 Mini</strong>: $0.25 input / $2.00 output.</li>
<li><strong>GPT-5 Nano</strong>: $0.05 input / $0.40 output.</li>
<li>A 90% discount is available for cached input tokens.</li>
</ul>
</li>
<li>
<p><strong>Training &amp; Safety</strong>:</p>
<ul>
<li><strong>Improvements</strong>: Focused on reducing hallucinations, sycophancy, and improving instruction following, particularly for writing, coding, and health queries.</li>
<li><strong>Safe-Completions</strong>: A new safety training approach that provides moderated, safe answers instead of binary refusals for potentially dual-use prompts.</li>
<li><strong>Deception Mitigation</strong>: The model is rewarded for admitting when a task is infeasible or when tools (e.g., web browsing) are unreliable.</li>
</ul>
</li>
<li>
<p><strong>Prompt Injection</strong>:</p>
<ul>
<li>Red-teaming resulted in a 56.8% attack success rate (with up to 10 attempts) against <code>gpt-5-thinking</code>.</li>
<li>While an improvement over other models, this indicates prompt injection remains an unsolved vulnerability.</li>
</ul>
</li>
<li>
<p><strong>API Features</strong>:</p>
<ul>
<li><strong>Thinking Traces</strong>: Reasoning steps can be accessed in the API response by setting <code>&quot;reasoning&quot;: {&quot;summary&quot;: &quot;auto&quot;}</code>.</li>
<li><strong>Latency Control</strong>: A <code>reasoning_effort=minimal</code> parameter is available to disable most reasoning and reduce response latency.</li>
</ul>
</li>
</ul></div></div><div class="ArticlePreview_ArticlePreview__59E_4"><div class="ArticlePreview_title__Snpua"><a target="_blank" href="https://world.hey.com/dhh/the-framework-desktop-is-a-beast-636fb4ff">The Framework Desktop is a beast</a></div><div class="ArticlePreview_tags__y8wnE"><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/hardware">hardware</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/desktop%20computer">desktop computer</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/mini%20pc">mini pc</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/framework">framework</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/framework%20desktop">framework desktop</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/amd">amd</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/ryzen">ryzen</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/apple">apple</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/m4">m4</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/mac%20studio">mac studio</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/intel">intel</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/nvidia">nvidia</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/rtx%204060">rtx 4060</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/cpu">cpu</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/gpu">gpu</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/unified%20memory">unified memory</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/small%20form%20factor">small form factor</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/sff">sff</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/performance">performance</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/benchmark">benchmark</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/geekbench">geekbench</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/development">development</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/docker">docker</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/gaming">gaming</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/ai">ai</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/large%20language%20models">large language models</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/llm">llm</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/review">review</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/value">value</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/pricing">pricing</a></div><div class="ArticlePreview_summary__Zyb4E"><ul>
<li><strong>CPU:</strong> AMD Ryzen AI Max 395+ (16 Zen5 cores @ 5.1GHz), a laptop-class processor.</li>
<li><strong>Form Factor:</strong> 4.5L volume, noted for being quiet even under full load.</li>
<li><strong>Multi-Core Performance:</strong>
<ul>
<li>Outperforms Apple M4 Max, M4 Pro, and Intel 14900K in Geekbench 6 multi-core benchmarks.</li>
<li>Excels in Docker-based development workflows (e.g., Ruby test suite with MySQL/Redis/ElasticSearch), showing a ~40% speed increase over an M4 Max, partially due to Docker&#x27;s native performance on Linux.</li>
</ul>
</li>
<li><strong>Single-Core Performance:</strong>
<ul>
<li>Approximately 20% slower than Apple&#x27;s M4 series in single-core tasks.</li>
<li>Speedometer 2.1 benchmark: 670 (vs. 744 on M4 Pro).</li>
</ul>
</li>
<li><strong>Memory:</strong>
<ul>
<li>Utilizes unified memory, configurable up to 128GB.</li>
<li>Suitable for running large local LLMs (e.g., 120b models at ~40 tokens/second).</li>
</ul>
</li>
<li><strong>Graphics:</strong>
<ul>
<li>Integrated GPU performance is comparable to a discrete NVIDIA RTX 4060.</li>
<li>Capable of running modern games at 1440p on high settings.</li>
</ul>
</li>
<li><strong>Value:</strong>
<ul>
<li>A 64GB RAM / 2TB NVMe configuration is priced at $1,876, nearly half the cost of a similarly specced Mac Studio ($3,299).</li>
<li>Positioned as a higher-performance, more expensive alternative to other mini PCs like the Beelink SER9.</li>
</ul>
</li>
</ul></div></div><div class="ArticlePreview_ArticlePreview__59E_4"><div class="ArticlePreview_title__Snpua"><a target="_blank" href="https://www.anthropic.com/news/1m-context">Claude Sonnet 4 now supports 1M tokens of context</a></div><div class="ArticlePreview_tags__y8wnE"><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/ai">ai</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/large%20language%20model">large language model</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/llm">llm</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/anthropic">anthropic</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/claude%20sonnet%204">claude sonnet 4</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/context%20window">context window</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/api">api</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/pricing">pricing</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/code%20analysis">code analysis</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/agentic%20workflows">agentic workflows</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/amazon%20bedrock">amazon bedrock</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/google%20cloud%20vertex%20ai">google cloud vertex ai</a></div><div class="ArticlePreview_summary__Zyb4E"><ul>
<li><strong>Model:</strong> Claude Sonnet 4</li>
<li><strong>Feature:</strong> Context window increased to 1 million tokens (public beta).</li>
<li><strong>Capacity:</strong> Supports processing entire codebases (~75,000+ lines) or extensive document sets in a single request.</li>
<li><strong>Use Cases:</strong> Large-scale code analysis, multi-document synthesis, and stateful agentic workflows with extensive tool definitions.</li>
<li><strong>Pricing (per million tokens):</strong>
<ul>
<li><strong>≤ 200K tokens:</strong> $3 (input), $15 (output)</li>
<li><strong>&gt; 200K tokens:</strong> $6 (input), $22.50 (output)</li>
</ul>
</li>
<li><strong>Cost Optimization:</strong> Compatible with prompt caching and batch processing (which provides a 50% cost reduction).</li>
<li><strong>Availability:</strong> Accessible via Anthropic API (for Tier 4+ customers) and Amazon Bedrock, with Google Cloud Vertex AI support forthcoming.</li>
</ul></div></div></div></div></div><!--$--><!--/$--><script src="/url-notes/_next/static/chunks/webpack-54d9d4b2aa649176.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[7555,[],\"\"]\n3:I[1295,[],\"\"]\n5:I[9665,[],\"OutletBoundary\"]\n7:I[4911,[],\"AsyncMetadataOutlet\"]\n9:I[9665,[],\"ViewportBoundary\"]\nb:I[9665,[],\"MetadataBoundary\"]\nc:\"$Sreact.suspense\"\ne:I[8393,[],\"\"]\n:HL[\"/url-notes/_next/static/css/f03c873af434c7c6.css\",\"style\"]\n:HL[\"/url-notes/_next/static/css/0e5ea1ea0183b412.css\",\"style\"]\n:HL[\"/url-notes/_next/static/css/7190d9c623ab1fe0.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"5-nUCfWPKUbKZCqW3krM4\",\"p\":\"/url-notes\",\"c\":[\"\",\"tag\",\"pricing\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"tag\",{\"children\":[[\"tag\",\"pricing\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/url-notes/_next/static/css/f03c873af434c7c6.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"children\":[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]}]]}],{\"children\":[\"tag\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"tag\",\"pricing\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$L4\",[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/url-notes/_next/static/css/0e5ea1ea0183b412.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"link\",\"1\",{\"rel\":\"stylesheet\",\"href\":\"/url-notes/_next/static/css/7190d9c623ab1fe0.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"$L5\",null,{\"children\":[\"$L6\",[\"$\",\"$L7\",null,{\"promise\":\"$@8\"}]]}]]}],{},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[[\"$\",\"$L9\",null,{\"children\":\"$La\"}],null],[\"$\",\"$Lb\",null,{\"children\":[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$c\",null,{\"fallback\":null,\"children\":\"$Ld\"}]}]}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$e\",[]],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"a:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n6:null\n"])</script><script>self.__next_f.push([1,"f:I[8175,[],\"IconMark\"]\n8:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"url-notes | tag | pricing\"}],[\"$\",\"link\",\"1\",{\"rel\":\"icon\",\"href\":\"/url-notes/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"256x256\"}],[\"$\",\"$Lf\",\"2\",{}]],\"error\":null,\"digest\":\"$undefined\"}\n"])</script><script>self.__next_f.push([1,"d:\"$8:metadata\"\n"])</script><script>self.__next_f.push([1,"10:I[6874,[\"874\",\"static/chunks/874-437a265a67d6cfee.js\",\"296\",\"static/chunks/app/tag/%5Btag%5D/page-abef1952a2d9d9ae.js\"],\"\"]\n"])</script><script>self.__next_f.push([1,"4:[\"$\",\"div\",null,{\"className\":\"$undefined\",\"children\":[[\"$\",\"div\",null,{\"className\":\"Header_Header__VDN4T\",\"children\":[[\"$\",\"div\",null,{\"className\":\"Header_item__PWJos\",\"children\":[\"$\",\"$L10\",null,{\"href\":\"/\",\"children\":\"url-notes\"}]}],[[[\"$\",\"div\",\"separator-0\",{\"className\":\"Header_separator__zF22U\",\"children\":\"|\"}],[\"$\",\"div\",\"item-0\",{\"className\":\"Header_item__PWJos\",\"children\":[\"$\",\"$L10\",\"0\",{\"href\":\"/tags\",\"children\":\"tag\"}]}]],[[\"$\",\"div\",\"separator-1\",{\"className\":\"Header_separator__zF22U\",\"children\":\"|\"}],[\"$\",\"div\",\"item-1\",{\"className\":\"Header_item__PWJos\",\"children\":[\"$\",\"$L10\",\"1\",{\"href\":\"/tags\",\"children\":\"tag\"}]}]],[[\"$\",\"div\",\"separator-2\",{\"className\":\"Header_separator__zF22U\",\"children\":\"|\"}],[\"$\",\"div\",\"item-2\",{\"className\":\"Header_item__PWJos\",\"children\":[\"$\",\"span\",\"2\",{\"children\":\"pricing\"}]}]]]]}],[\"$\",\"div\",null,{\"className\":\"page_content__fAQW6\",\"children\":[\"$\",\"div\",null,{\"className\":\"page_previews__SpAnf\",\"children\":[[\"$\",\"div\",\"0\",{\"className\":\"ArticlePreview_ArticlePreview__59E_4\",\"children\":[[\"$\",\"div\",null,{\"className\":\"ArticlePreview_title__Snpua\",\"children\":[\"$\",\"$L10\",null,{\"href\":\"https://simonwillison.net/2025/Aug/7/gpt-5/\",\"target\":\"_blank\",\"children\":\"GPT-5: Key characteristics, pricing and model card\"}]}],[\"$\",\"div\",null,{\"className\":\"ArticlePreview_tags__y8wnE\",\"children\":[[\"$\",\"$L10\",\"0\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/ai\",\"children\":\"ai\"}],[\"$\",\"$L10\",\"1\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/gpt-5\",\"children\":\"gpt-5\"}],[\"$\",\"$L10\",\"2\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/large%20language%20models\",\"children\":\"large language models\"}],[\"$\",\"$L10\",\"3\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/openai\",\"children\":\"openai\"}],[\"$\",\"$L10\",\"4\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/machine%20learning\",\"children\":\"machine learning\"}],[\"$\",\"$L10\",\"5\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/technology\",\"children\":\"technology\"}],[\"$\",\"$L10\",\"6\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/api\",\"children\":\"api\"}],[\"$\",\"$L10\",\"7\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/pricing\",\"children\":\"pricing\"}],[\"$\",\"$L10\",\"8\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/ai%20safety\",\"children\":\"ai safety\"}],[\"$\",\"$L10\",\"9\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/prompt%20injection\",\"children\":\"prompt injection\"}],[\"$\",\"$L10\",\"10\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/reasoning\",\"children\":\"reasoning\"}],[\"$\",\"$L10\",\"11\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/multimodality\",\"children\":\"multimodality\"}]]}],[\"$\",\"div\",null,{\"className\":\"ArticlePreview_summary__Zyb4E\",\"children\":[[\"$\",\"ul\",\"ul-0\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":[\"\\n\",[\"$\",\"p\",\"p-0\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Model Architecture\"}],\":\"]}],\"\\n\",[\"$\",\"ul\",\"ul-0\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"ChatGPT Interface\"}],\": A hybrid system using a real-time router to select between a \\\"smart and fast\\\" model for most queries and a \\\"deeper reasoning\\\" model for complex problems. A \\\"mini\\\" version is used when usage limits are reached.\"]}],\"\\n\",[\"$\",\"li\",\"li-1\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"API Access\"}],\": Offered as three distinct models: \",[\"$\",\"code\",\"code-0\",{\"children\":\"gpt-5\"}],\" (regular), \",[\"$\",\"code\",\"code-1\",{\"children\":\"gpt-5-mini\"}],\", and \",[\"$\",\"code\",\"code-2\",{\"children\":\"gpt-5-nano\"}],\".\"]}],\"\\n\",[\"$\",\"li\",\"li-2\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Reasoning Levels\"}],\": Each API model can be configured with four reasoning levels: minimal, low, medium, or high.\"]}],\"\\n\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"li\",\"li-1\",{\"children\":[\"\\n\",[\"$\",\"p\",\"p-0\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Technical Specifications\"}],\":\"]}],\"\\n\",[\"$\",\"ul\",\"ul-0\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Context Window\"}],\": 272,000 input tokens.\"]}],\"\\n\",[\"$\",\"li\",\"li-1\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Output Limit\"}],\": 128,000 tokens (includes \\\"invisible\\\" reasoning tokens).\"]}],\"\\n\",[\"$\",\"li\",\"li-2\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Modalities\"}],\": Supports text and image input; text-only output.\"]}],\"\\n\",[\"$\",\"li\",\"li-3\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Knowledge Cutoff\"}],\": September 30, 2024 for GPT-5; May 30, 2024 for mini and nano versions.\"]}],\"\\n\"]}],\"\\n\"]}],\"\\n\",\"$L11\",\"\\n\",\"$L12\",\"\\n\",\"$L13\",\"\\n\",\"$L14\",\"\\n\"]}]]}]]}],\"$L15\",\"$L16\"]}]}]]}]\n"])</script><script>self.__next_f.push([1,"11:[\"$\",\"li\",\"li-2\",{\"children\":[\"\\n\",[\"$\",\"p\",\"p-0\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Pricing (per million tokens)\"}],\":\"]}],\"\\n\",[\"$\",\"ul\",\"ul-0\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"GPT-5\"}],\": $1.25 input / $10.00 output.\"]}],\"\\n\",[\"$\",\"li\",\"li-1\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"GPT-5 Mini\"}],\": $0.25 input / $2.00 output.\"]}],\"\\n\",[\"$\",\"li\",\"li-2\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"GPT-5 Nano\"}],\": $0.05 input / $0.40 output.\"]}],\"\\n\",[\"$\",\"li\",\"li-3\",{\"children\":\"A 90% discount is available for cached input tokens.\"}],\"\\n\"]}],\"\\n\"]}]\n"])</script><script>self.__next_f.push([1,"12:[\"$\",\"li\",\"li-3\",{\"children\":[\"\\n\",[\"$\",\"p\",\"p-0\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Training \u0026 Safety\"}],\":\"]}],\"\\n\",[\"$\",\"ul\",\"ul-0\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Improvements\"}],\": Focused on reducing hallucinations, sycophancy, and improving instruction following, particularly for writing, coding, and health queries.\"]}],\"\\n\",[\"$\",\"li\",\"li-1\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Safe-Completions\"}],\": A new safety training approach that provides moderated, safe answers instead of binary refusals for potentially dual-use prompts.\"]}],\"\\n\",[\"$\",\"li\",\"li-2\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Deception Mitigation\"}],\": The model is rewarded for admitting when a task is infeasible or when tools (e.g., web browsing) are unreliable.\"]}],\"\\n\"]}],\"\\n\"]}]\n"])</script><script>self.__next_f.push([1,"13:[\"$\",\"li\",\"li-4\",{\"children\":[\"\\n\",[\"$\",\"p\",\"p-0\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Prompt Injection\"}],\":\"]}],\"\\n\",[\"$\",\"ul\",\"ul-0\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":[\"Red-teaming resulted in a 56.8% attack success rate (with up to 10 attempts) against \",[\"$\",\"code\",\"code-0\",{\"children\":\"gpt-5-thinking\"}],\".\"]}],\"\\n\",[\"$\",\"li\",\"li-1\",{\"children\":\"While an improvement over other models, this indicates prompt injection remains an unsolved vulnerability.\"}],\"\\n\"]}],\"\\n\"]}]\n14:[\"$\",\"li\",\"li-5\",{\"children\":[\"\\n\",[\"$\",\"p\",\"p-0\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"API Features\"}],\":\"]}],\"\\n\",[\"$\",\"ul\",\"ul-0\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Thinking Traces\"}],\": Reasoning steps can be accessed in the API response by setting \",[\"$\",\"code\",\"code-0\",{\"children\":\"\\\"reasoning\\\": {\\\"summary\\\": \\\"auto\\\"}\"}],\".\"]}],\"\\n\",[\"$\",\"li\",\"li-1\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Latency Control\"}],\": A \",[\"$\",\"code\",\"code-0\",{\"children\":\"reasoning_effort=minimal\"}],\" parameter is available to disable most reasoning and reduce response latency.\"]}],\"\\n\"]}],\"\\n\"]}]\n"])</script><script>self.__next_f.push([1,"15:[\"$\",\"div\",\"1\",{\"className\":\"ArticlePreview_ArticlePreview__59E_4\",\"children\":[[\"$\",\"div\",null,{\"className\":\"ArticlePreview_title__Snpua\",\"children\":[\"$\",\"$L10\",null,{\"href\":\"https://world.hey.com/dhh/the-framework-desktop-is-a-beast-636fb4ff\",\"target\":\"_blank\",\"children\":\"The Framework Desktop is a beast\"}]}],[\"$\",\"div\",null,{\"className\":\"ArticlePreview_tags__y8wnE\",\"children\":[[\"$\",\"$L10\",\"0\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/hardware\",\"children\":\"hardware\"}],[\"$\",\"$L10\",\"1\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/desktop%20computer\",\"children\":\"desktop computer\"}],[\"$\",\"$L10\",\"2\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/mini%20pc\",\"children\":\"mini pc\"}],[\"$\",\"$L10\",\"3\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/framework\",\"children\":\"framework\"}],[\"$\",\"$L10\",\"4\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/framework%20desktop\",\"children\":\"framework desktop\"}],[\"$\",\"$L10\",\"5\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/amd\",\"children\":\"amd\"}],[\"$\",\"$L10\",\"6\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/ryzen\",\"children\":\"ryzen\"}],[\"$\",\"$L10\",\"7\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/apple\",\"children\":\"apple\"}],[\"$\",\"$L10\",\"8\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/m4\",\"children\":\"m4\"}],[\"$\",\"$L10\",\"9\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/mac%20studio\",\"children\":\"mac studio\"}],[\"$\",\"$L10\",\"10\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/intel\",\"children\":\"intel\"}],[\"$\",\"$L10\",\"11\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/nvidia\",\"children\":\"nvidia\"}],[\"$\",\"$L10\",\"12\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/rtx%204060\",\"children\":\"rtx 4060\"}],[\"$\",\"$L10\",\"13\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/cpu\",\"children\":\"cpu\"}],[\"$\",\"$L10\",\"14\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/gpu\",\"children\":\"gpu\"}],[\"$\",\"$L10\",\"15\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/unified%20memory\",\"children\":\"unified memory\"}],[\"$\",\"$L10\",\"16\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/small%20form%20factor\",\"children\":\"small form factor\"}],[\"$\",\"$L10\",\"17\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/sff\",\"children\":\"sff\"}],[\"$\",\"$L10\",\"18\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/performance\",\"children\":\"performance\"}],[\"$\",\"$L10\",\"19\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/benchmark\",\"children\":\"benchmark\"}],[\"$\",\"$L10\",\"20\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/geekbench\",\"children\":\"geekbench\"}],[\"$\",\"$L10\",\"21\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/development\",\"children\":\"development\"}],[\"$\",\"$L10\",\"22\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/docker\",\"children\":\"docker\"}],[\"$\",\"$L10\",\"23\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/gaming\",\"children\":\"gaming\"}],[\"$\",\"$L10\",\"24\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/ai\",\"children\":\"ai\"}],[\"$\",\"$L10\",\"25\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/large%20language%20models\",\"children\":\"large language models\"}],[\"$\",\"$L10\",\"26\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/llm\",\"children\":\"llm\"}],[\"$\",\"$L10\",\"27\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/review\",\"children\":\"review\"}],[\"$\",\"$L10\",\"28\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/value\",\"children\":\"value\"}],[\"$\",\"$L10\",\"29\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/pricing\",\"children\":\"pricing\"}]]}],[\"$\",\"div\",null,{\"className\":\"ArticlePreview_summary__Zyb4E\",\"children\":[[\"$\",\"ul\",\"ul-0\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"CPU:\"}],\" AMD Ryzen AI Max 395+ (16 Zen5 cores @ 5.1GHz), a laptop-class processor.\"]}],\"\\n\",[\"$\",\"li\",\"li-1\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Form Factor:\"}],\" 4.5L volume, noted for being quiet even under full load.\"]}],\"\\n\",[\"$\",\"li\",\"li-2\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Multi-Core Performance:\"}],\"\\n\",[\"$\",\"ul\",\"ul-0\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":\"Outperforms Apple M4 Max, M4 Pro, and Intel 14900K in Geekbench 6 multi-core benchmarks.\"}],\"\\n\",[\"$\",\"li\",\"li-1\",{\"children\":\"Excels in Docker-based development workflows (e.g., Ruby test suite with MySQL/Redis/ElasticSearch), showing a ~40% speed increase over an M4 Max, partially due to Docker's native performance on Linux.\"}],\"\\n\"]}],\"\\n\"]}],\"\\n\",\"$L17\",\"\\n\",\"$L18\",\"\\n\",\"$L19\",\"\\n\",\"$L1a\",\"\\n\"]}]]}]]}]\n"])</script><script>self.__next_f.push([1,"16:[\"$\",\"div\",\"2\",{\"className\":\"ArticlePreview_ArticlePreview__59E_4\",\"children\":[[\"$\",\"div\",null,{\"className\":\"ArticlePreview_title__Snpua\",\"children\":[\"$\",\"$L10\",null,{\"href\":\"https://www.anthropic.com/news/1m-context\",\"target\":\"_blank\",\"children\":\"Claude Sonnet 4 now supports 1M tokens of context\"}]}],[\"$\",\"div\",null,{\"className\":\"ArticlePreview_tags__y8wnE\",\"children\":[[\"$\",\"$L10\",\"0\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/ai\",\"children\":\"ai\"}],[\"$\",\"$L10\",\"1\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/large%20language%20model\",\"children\":\"large language model\"}],[\"$\",\"$L10\",\"2\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/llm\",\"children\":\"llm\"}],[\"$\",\"$L10\",\"3\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/anthropic\",\"children\":\"anthropic\"}],[\"$\",\"$L10\",\"4\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/claude%20sonnet%204\",\"children\":\"claude sonnet 4\"}],[\"$\",\"$L10\",\"5\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/context%20window\",\"children\":\"context window\"}],[\"$\",\"$L10\",\"6\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/api\",\"children\":\"api\"}],[\"$\",\"$L10\",\"7\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/pricing\",\"children\":\"pricing\"}],[\"$\",\"$L10\",\"8\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/code%20analysis\",\"children\":\"code analysis\"}],[\"$\",\"$L10\",\"9\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/agentic%20workflows\",\"children\":\"agentic workflows\"}],[\"$\",\"$L10\",\"10\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/amazon%20bedrock\",\"children\":\"amazon bedrock\"}],[\"$\",\"$L10\",\"11\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/google%20cloud%20vertex%20ai\",\"children\":\"google cloud vertex ai\"}]]}],[\"$\",\"div\",null,{\"className\":\"ArticlePreview_summary__Zyb4E\",\"children\":[[\"$\",\"ul\",\"ul-0\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Model:\"}],\" Claude Sonnet 4\"]}],\"\\n\",[\"$\",\"li\",\"li-1\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Feature:\"}],\" Context window increased to 1 million tokens (public beta).\"]}],\"\\n\",[\"$\",\"li\",\"li-2\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Capacity:\"}],\" Supports processing entire codebases (~75,000+ lines) or extensive document sets in a single request.\"]}],\"\\n\",[\"$\",\"li\",\"li-3\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Use Cases:\"}],\" Large-scale code analysis, multi-document synthesis, and stateful agentic workflows with extensive tool definitions.\"]}],\"\\n\",[\"$\",\"li\",\"li-4\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Pricing (per million tokens):\"}],\"\\n\",[\"$\",\"ul\",\"ul-0\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"≤ 200K tokens:\"}],\" $3 (input), $15 (output)\"]}],\"\\n\",[\"$\",\"li\",\"li-1\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"\u003e 200K tokens:\"}],\" $6 (input), $22.50 (output)\"]}],\"\\n\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"li\",\"li-5\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Cost Optimization:\"}],\" Compatible with prompt caching and batch processing (which provides a 50% cost reduction).\"]}],\"\\n\",[\"$\",\"li\",\"li-6\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Availability:\"}],\" Accessible via Anthropic API (for Tier 4+ customers) and Amazon Bedrock, with Google Cloud Vertex AI support forthcoming.\"]}],\"\\n\"]}]]}]]}]\n"])</script><script>self.__next_f.push([1,"17:[\"$\",\"li\",\"li-3\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Single-Core Performance:\"}],\"\\n\",[\"$\",\"ul\",\"ul-0\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":\"Approximately 20% slower than Apple's M4 series in single-core tasks.\"}],\"\\n\",[\"$\",\"li\",\"li-1\",{\"children\":\"Speedometer 2.1 benchmark: 670 (vs. 744 on M4 Pro).\"}],\"\\n\"]}],\"\\n\"]}]\n18:[\"$\",\"li\",\"li-4\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Memory:\"}],\"\\n\",[\"$\",\"ul\",\"ul-0\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":\"Utilizes unified memory, configurable up to 128GB.\"}],\"\\n\",[\"$\",\"li\",\"li-1\",{\"children\":\"Suitable for running large local LLMs (e.g., 120b models at ~40 tokens/second).\"}],\"\\n\"]}],\"\\n\"]}]\n19:[\"$\",\"li\",\"li-5\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Graphics:\"}],\"\\n\",[\"$\",\"ul\",\"ul-0\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":\"Integrated GPU performance is comparable to a discrete NVIDIA RTX 4060.\"}],\"\\n\",[\"$\",\"li\",\"li-1\",{\"children\":\"Capable of running modern games at 1440p on high settings.\"}],\"\\n\"]}],\"\\n\"]}]\n1a:[\"$\",\"li\",\"li-6\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Value:\"}],\"\\n\",[\"$\",\"ul\",\"ul-0\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":\"A 64GB RAM / 2TB NVMe configuration is priced at $1,876, nearly half the cost of a similarly specced Mac Studio ($3,299).\"}],\"\\n\",[\"$\",\"li\",\"li-1\",{\"children\":\"Positioned as a higher-performance, more expensive alternative to other mini PCs like the Beelink SER9.\"}],\"\\n\"]}],\"\\n\"]}]\n"])</script></body></html>