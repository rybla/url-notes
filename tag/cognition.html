<!DOCTYPE html><!--2ftq9q065sAN0hXaaQYev--><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/url-notes/_next/static/css/f03c873af434c7c6.css" data-precedence="next"/><link rel="stylesheet" href="/url-notes/_next/static/css/dcd3d4e1f4857066.css" data-precedence="next"/><link rel="stylesheet" href="/url-notes/_next/static/css/a9d1307f18e49070.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/url-notes/_next/static/chunks/webpack-085376ced4d6856e.js"/><script src="/url-notes/_next/static/chunks/4bd1b696-cf72ae8a39fa05aa.js" async=""></script><script src="/url-notes/_next/static/chunks/964-a29425d4972030f1.js" async=""></script><script src="/url-notes/_next/static/chunks/main-app-e4d4697bcd6cfe75.js" async=""></script><script src="/url-notes/_next/static/chunks/874-437a265a67d6cfee.js" async=""></script><script src="/url-notes/_next/static/chunks/app/tag/%5Btag%5D/page-42d05b4590119831.js" async=""></script><title>url-notes | tag | cognition</title><link rel="icon" href="/url-notes/favicon.ico" type="image/x-icon" sizes="256x256"/><script src="/url-notes/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body><div hidden=""><!--$--><!--/$--></div><div><div class="Header_Header__VDN4T"><div class="Header_item__PWJos"><a href="/url-notes">url-notes</a></div><div class="Header_separator__zF22U">|</div><div class="Header_item__PWJos"><a href="/url-notes/tags">tag</a></div><div class="Header_separator__zF22U">|</div><div class="Header_item__PWJos"><a href="/url-notes/tags">tag</a></div><div class="Header_separator__zF22U">|</div><div class="Header_item__PWJos"><span>cognition</span></div></div><div class="page_content__fAQW6"><div class="page_previews__SpAnf"><div class="ArticlePreview_ArticlePreview__59E_4"><div class="ArticlePreview_title__Snpua"><a target="_blank" href="https://zed.dev/blog/why-llms-cant-build-software">Why LLMs Can&#x27;t Really Build Software - Zed Blog</a></div><div class="ArticlePreview_tags__y8wnE"><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/llm">llm</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/software%20engineering">software engineering</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/mental%20models">mental models</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/ai">ai</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/programming">programming</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/ai%20limitations">ai limitations</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/autonomous%20agents">autonomous agents</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/cognition">cognition</a><a class="ArticlePreview_tag___oIyn" href="/url-notes/tag/software%20development">software development</a></div><div class="ArticlePreview_summary__Zyb4E"><ul>
<li><strong>Core Thesis:</strong> LLMs cannot effectively build non-trivial software because they are incapable of creating, maintaining, and comparing the two distinct mental models essential for engineering: the model of the <em>requirements</em> and the model of what the <em>code actually does</em>.</li>
<li><strong>Effective Software Engineering Loop:</strong>
<ol>
<li>Build a mental model of requirements.</li>
<li>Write code to implement the model.</li>
<li>Build a mental model of the code&#x27;s actual behavior.</li>
<li>Identify discrepancies and iterate on code or requirements.</li>
</ol>
</li>
<li><strong>LLM Failures in the Loop:</strong>
<ul>
<li>LLMs cannot reliably perform step 3 or 4. They struggle to form an accurate model of the code they&#x27;ve written and get confused when tests fail, guessing whether to fix the code or the tests.</li>
<li>They lack the ability to &quot;zoom&quot; in and out of context levels or to temporarily stash a problem&#x27;s context to solve a sub-problem, unlike human engineers.</li>
</ul>
</li>
<li><strong>Identified Technical Weaknesses:</strong>
<ul>
<li><strong>Context Omission:</strong> Models fail to acquire relevant context that is not explicitly provided.</li>
<li><strong>Recency Bias:</strong> Model outputs are disproportionately influenced by the most recent information in the context window.</li>
<li><strong>Hallucination:</strong> Models generate plausible but incorrect details.</li>
</ul>
</li>
<li><strong>Conclusion:</strong> While useful for generating code for simple, well-defined tasks, LLMs currently function as a tool, not an autonomous engineer. The human developer remains responsible for driving the development process by managing the core mental models and verifying the output.</li>
</ul></div></div></div></div></div><!--$--><!--/$--><script src="/url-notes/_next/static/chunks/webpack-085376ced4d6856e.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[7555,[],\"\"]\n3:I[1295,[],\"\"]\n5:I[9665,[],\"OutletBoundary\"]\n7:I[4911,[],\"AsyncMetadataOutlet\"]\n9:I[9665,[],\"ViewportBoundary\"]\nb:I[9665,[],\"MetadataBoundary\"]\nc:\"$Sreact.suspense\"\ne:I[8393,[],\"\"]\n:HL[\"/url-notes/_next/static/css/f03c873af434c7c6.css\",\"style\"]\n:HL[\"/url-notes/_next/static/css/dcd3d4e1f4857066.css\",\"style\"]\n:HL[\"/url-notes/_next/static/css/a9d1307f18e49070.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"2ftq9q065sAN0hXaaQYev\",\"p\":\"/url-notes\",\"c\":[\"\",\"tag\",\"cognition\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"tag\",{\"children\":[[\"tag\",\"cognition\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/url-notes/_next/static/css/f03c873af434c7c6.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"children\":[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]}]]}],{\"children\":[\"tag\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"tag\",\"cognition\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$L4\",[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/url-notes/_next/static/css/dcd3d4e1f4857066.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"link\",\"1\",{\"rel\":\"stylesheet\",\"href\":\"/url-notes/_next/static/css/a9d1307f18e49070.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"$L5\",null,{\"children\":[\"$L6\",[\"$\",\"$L7\",null,{\"promise\":\"$@8\"}]]}]]}],{},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[[\"$\",\"$L9\",null,{\"children\":\"$La\"}],null],[\"$\",\"$Lb\",null,{\"children\":[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$c\",null,{\"fallback\":null,\"children\":\"$Ld\"}]}]}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$e\",[]],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"a:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n6:null\n"])</script><script>self.__next_f.push([1,"f:I[8175,[],\"IconMark\"]\n8:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"url-notes | tag | cognition\"}],[\"$\",\"link\",\"1\",{\"rel\":\"icon\",\"href\":\"/url-notes/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"256x256\"}],[\"$\",\"$Lf\",\"2\",{}]],\"error\":null,\"digest\":\"$undefined\"}\n"])</script><script>self.__next_f.push([1,"d:\"$8:metadata\"\n"])</script><script>self.__next_f.push([1,"10:I[6874,[\"874\",\"static/chunks/874-437a265a67d6cfee.js\",\"296\",\"static/chunks/app/tag/%5Btag%5D/page-42d05b4590119831.js\"],\"\"]\n"])</script><script>self.__next_f.push([1,"4:[\"$\",\"div\",null,{\"className\":\"$undefined\",\"children\":[[\"$\",\"div\",null,{\"className\":\"Header_Header__VDN4T\",\"children\":[[\"$\",\"div\",null,{\"className\":\"Header_item__PWJos\",\"children\":[\"$\",\"$L10\",null,{\"href\":\"/\",\"children\":\"url-notes\"}]}],[[[\"$\",\"div\",\"separator-0\",{\"className\":\"Header_separator__zF22U\",\"children\":\"|\"}],[\"$\",\"div\",\"item-0\",{\"className\":\"Header_item__PWJos\",\"children\":[\"$\",\"$L10\",\"0\",{\"href\":\"/tags\",\"children\":\"tag\"}]}]],[[\"$\",\"div\",\"separator-1\",{\"className\":\"Header_separator__zF22U\",\"children\":\"|\"}],[\"$\",\"div\",\"item-1\",{\"className\":\"Header_item__PWJos\",\"children\":[\"$\",\"$L10\",\"1\",{\"href\":\"/tags\",\"children\":\"tag\"}]}]],[[\"$\",\"div\",\"separator-2\",{\"className\":\"Header_separator__zF22U\",\"children\":\"|\"}],[\"$\",\"div\",\"item-2\",{\"className\":\"Header_item__PWJos\",\"children\":[\"$\",\"span\",\"2\",{\"children\":\"cognition\"}]}]]]]}],[\"$\",\"div\",null,{\"className\":\"page_content__fAQW6\",\"children\":[\"$\",\"div\",null,{\"className\":\"page_previews__SpAnf\",\"children\":[[\"$\",\"div\",\"0\",{\"className\":\"ArticlePreview_ArticlePreview__59E_4\",\"children\":[[\"$\",\"div\",null,{\"className\":\"ArticlePreview_title__Snpua\",\"children\":[\"$\",\"$L10\",null,{\"href\":\"https://zed.dev/blog/why-llms-cant-build-software\",\"target\":\"_blank\",\"children\":\"Why LLMs Can't Really Build Software - Zed Blog\"}]}],[\"$\",\"div\",null,{\"className\":\"ArticlePreview_tags__y8wnE\",\"children\":[[\"$\",\"$L10\",\"0\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/llm\",\"children\":\"llm\"}],[\"$\",\"$L10\",\"1\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/software%20engineering\",\"children\":\"software engineering\"}],[\"$\",\"$L10\",\"2\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/mental%20models\",\"children\":\"mental models\"}],[\"$\",\"$L10\",\"3\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/ai\",\"children\":\"ai\"}],[\"$\",\"$L10\",\"4\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/programming\",\"children\":\"programming\"}],[\"$\",\"$L10\",\"5\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/ai%20limitations\",\"children\":\"ai limitations\"}],[\"$\",\"$L10\",\"6\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/autonomous%20agents\",\"children\":\"autonomous agents\"}],[\"$\",\"$L10\",\"7\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/cognition\",\"children\":\"cognition\"}],[\"$\",\"$L10\",\"8\",{\"className\":\"ArticlePreview_tag___oIyn\",\"href\":\"/tag/software%20development\",\"children\":\"software development\"}]]}],[\"$\",\"div\",null,{\"className\":\"ArticlePreview_summary__Zyb4E\",\"children\":[[\"$\",\"ul\",\"ul-0\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Core Thesis:\"}],\" LLMs cannot effectively build non-trivial software because they are incapable of creating, maintaining, and comparing the two distinct mental models essential for engineering: the model of the \",[\"$\",\"em\",\"em-0\",{\"children\":\"requirements\"}],\" and the model of what the \",[\"$\",\"em\",\"em-1\",{\"children\":\"code actually does\"}],\".\"]}],\"\\n\",[\"$\",\"li\",\"li-1\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Effective Software Engineering Loop:\"}],\"\\n\",[\"$\",\"ol\",\"ol-0\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":\"Build a mental model of requirements.\"}],\"\\n\",[\"$\",\"li\",\"li-1\",{\"children\":\"Write code to implement the model.\"}],\"\\n\",[\"$\",\"li\",\"li-2\",{\"children\":\"Build a mental model of the code's actual behavior.\"}],\"\\n\",[\"$\",\"li\",\"li-3\",{\"children\":\"Identify discrepancies and iterate on code or requirements.\"}],\"\\n\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"li\",\"li-2\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"LLM Failures in the Loop:\"}],\"\\n\",[\"$\",\"ul\",\"ul-0\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":\"LLMs cannot reliably perform step 3 or 4. They struggle to form an accurate model of the code they've written and get confused when tests fail, guessing whether to fix the code or the tests.\"}],\"\\n\",[\"$\",\"li\",\"li-1\",{\"children\":\"They lack the ability to \\\"zoom\\\" in and out of context levels or to temporarily stash a problem's context to solve a sub-problem, unlike human engineers.\"}],\"\\n\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"li\",\"li-3\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Identified Technical Weaknesses:\"}],\"\\n\",[\"$\",\"ul\",\"ul-0\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Context Omission:\"}],\" Models fail to acquire relevant context that is not explicitly provided.\"]}],\"\\n\",[\"$\",\"li\",\"li-1\",{\"children\":[\"$L11\",\" Model outputs are disproportionately influenced by the most recent information in the context window.\"]}],\"\\n\",\"$L12\",\"\\n\"]}],\"\\n\"]}],\"\\n\",\"$L13\",\"\\n\"]}]]}]]}]]}]}]]}]\n"])</script><script>self.__next_f.push([1,"11:[\"$\",\"strong\",\"strong-0\",{\"children\":\"Recency Bias:\"}]\n12:[\"$\",\"li\",\"li-2\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Hallucination:\"}],\" Models generate plausible but incorrect details.\"]}]\n13:[\"$\",\"li\",\"li-4\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"Conclusion:\"}],\" While useful for generating code for simple, well-defined tasks, LLMs currently function as a tool, not an autonomous engineer. The human developer remains responsible for driving the development process by managing the core mental models and verifying the output.\"]}]\n"])</script></body></html>